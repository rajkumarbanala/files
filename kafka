Kafka:
---------------------------------------------------------------------------------
- event/message
	- contains key, value, timestamp, optional metadata headers
- producers
	- client app's publish(write events to kafka)
- consumers
	- client app's subscribe(read & process events from kafka)
- topic
	- contains name
	- can have multi-producer and multi-subscriber.
	- stores events & it won't delete after consumption.
	- can configure how long to store events per topic.
	- Topics are partitioned
		- spread over a number of "buckets" located on different Kafka brokers
		- client applications to both read and write the data from/to many brokers at the same time
		- Events with the same event key (e.g., a customer or vehicle ID) are written to the same partition
		- multiple brokers that have a copy of the data just in case things go wrong, you want to do maintenance on the brokers, and so on.
		- A common production setting is a replication factor of 3, i.e., there will always be three copies of your data.
		- This replication is performed at the level of topic-partitions.
		
kafka cmds:
---------------------------------------------------------------------------------
topic create: ./kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
topic delete: ./kafka-topics.sh --delete --topic quickstart-events --bootstrap-server localhost:9092
topic list: ./kafka-topics.sh --list --bootstrap-server localhost:9092
topic view: ./kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
